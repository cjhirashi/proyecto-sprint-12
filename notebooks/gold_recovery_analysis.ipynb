{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ba799e",
   "metadata": {},
   "source": [
    "# 1. Optimización de Recuperación de Oro\n",
    "\n",
    "Proyecto de Machine Learning para la optimización de procesos industriales de recuperación de oro mediante la predicción de eficiencia en las etapas de flotación y purificación. El modelo predice la recuperación de oro tanto en el concentrado rougher como en el concentrado final, utilizando datos de sensores del proceso minero y parámetros operacionales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78422fdf",
   "metadata": {},
   "source": [
    "## 1.1 Alcance y criterios\n",
    "\n",
    "En esta sección se definen los lineamientos iniciales del proyecto para garantizar orden y reproducibilidad.\n",
    "\n",
    "**Objetivo:**  \n",
    "Establecer el entorno de trabajo, parámetros y utilidades del proyecto antes de la carga y exploración de datos.\n",
    "\n",
    "**Qué haremos aquí:**\n",
    "1. Cargar librerías y verificar versiones  \n",
    "2. Definir parámetros globales (rutas de datos, pesos de la métrica, semilla de aleatoriedad)  \n",
    "3. Configurar estilo visual básico para gráficos  \n",
    "4. Preparar importación de utilidades desde `src/` con fallback en caso de no encontrarlas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b695af8",
   "metadata": {},
   "source": [
    "## 1.2 Parámetros globales y configuración inicial\n",
    "\n",
    "En esta sección se consolidan los elementos necesarios para la configuración inicial del proyecto:  \n",
    "- Importación de librerías principales  \n",
    "- Verificación de versiones del entorno  \n",
    "- Configuración visual para las gráficas  \n",
    "- Definición de rutas de datos  \n",
    "- Variables objetivo y pesos de la métrica final\n",
    "\n",
    "Este bloque asegura que el entorno sea reproducible y consistente durante todo el desarrollo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9b39507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Versiones detectadas: {'python': '3.11.13', 'numpy': '1.24.4', 'pandas': '2.1.4', 'matplotlib': '3.7.3', 'seaborn': '0.12.2', 'scikit-learn': '1.3.2', 'scipy': '1.11.4'}\n",
      "✔️ Parámetros establecidos\n",
      "DATA_DIR: ../datasets\n",
      "TARGETS: ['rougher.output.recovery', 'final.output.recovery']\n",
      "Pesos métrica final → W_rougher=0.25, W_final=0.75\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Parámetros globales y configuración inicial\n",
    "\n",
    "# Librerías principales\n",
    "import os, sys, platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import scipy\n",
    "\n",
    "# Reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Verificación de versiones\n",
    "versions = {\n",
    "    \"python\": platform.python_version(),\n",
    "    \"numpy\": np.__version__,\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"matplotlib\": plt.matplotlib.__version__,\n",
    "    \"seaborn\": sns.__version__,\n",
    "    \"scikit-learn\": sklearn.__version__,\n",
    "    \"scipy\": scipy.__version__,\n",
    "}\n",
    "print(\"✔️ Versiones detectadas:\", versions)\n",
    "\n",
    "# Configuración visual\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Rutas de datos\n",
    "DATA_DIR   = \"../datasets\"\n",
    "TRAIN_PATH = f\"{DATA_DIR}/gold_recovery_train.csv\"\n",
    "TEST_PATH  = f\"{DATA_DIR}/gold_recovery_test.csv\"\n",
    "FULL_PATH  = f\"{DATA_DIR}/gold_recovery_full.csv\"\n",
    "\n",
    "# Variables objetivo\n",
    "TARGETS = [\"rougher.output.recovery\", \"final.output.recovery\"]\n",
    "\n",
    "# Pesos de la métrica final\n",
    "W_ROUGHER = 0.25\n",
    "W_FINAL   = 0.75\n",
    "\n",
    "print(\"✔️ Parámetros establecidos\")\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"TARGETS:\", TARGETS)\n",
    "print(f\"Pesos métrica final → W_rougher={W_ROUGHER}, W_final={W_FINAL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e153e8b1",
   "metadata": {},
   "source": [
    "### ✅ Conclusión — Sección 1.2 (Parámetros globales y configuración inicial)\n",
    "\n",
    "- El entorno se encuentra correctamente configurado con versiones actualizadas y compatibles:  \n",
    "  Python 3.11.13, NumPy 1.24.4, Pandas 2.1.4, Matplotlib 3.7.3, Seaborn 0.12.2, Scikit-learn 1.3.2 y SciPy 1.11.4.  \n",
    "- Se establecieron los parámetros clave del proyecto: rutas de los datasets, variables objetivo (`rougher.output.recovery` y `final.output.recovery`) y los pesos de la métrica final (0.25 para rougher, 0.75 para final).  \n",
    "- El estilo visual quedó definido con Matplotlib y Seaborn para garantizar uniformidad en las gráficas.  \n",
    "- Estado: la configuración inicial está completa y lista para avanzar a la carga y validación de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49fef8",
   "metadata": {},
   "source": [
    "# 2. Preparación de Datos\n",
    "\n",
    "Esta sección tiene como propósito garantizar que los datos estén correctamente cargados, validados y preprocesados antes del análisis exploratorio y la construcción del modelo. \n",
    "Aquí se realizan verificaciones de calidad, integridad y consistencia para asegurar que la información sea confiable y adecuada para su posterior uso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba33cc7",
   "metadata": {},
   "source": [
    "## 2.1 Carga y exploración inicial de datasets\n",
    "\n",
    "En esta subsección se realiza la importación de los conjuntos de datos de entrenamiento, prueba y completo. \n",
    "Se inspeccionan dimensiones, tipos de variables y valores nulos para obtener una primera impresión de la calidad y estructura de la información disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1cd293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los datasets:\n",
      "Train: (16860, 86)\n",
      "Test : (5856, 52)\n",
      "Full : (22716, 86)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final.output.concentrate_ag</th>\n",
       "      <th>final.output.concentrate_pb</th>\n",
       "      <th>final.output.concentrate_sol</th>\n",
       "      <th>final.output.concentrate_au</th>\n",
       "      <th>final.output.recovery</th>\n",
       "      <th>final.output.tail_ag</th>\n",
       "      <th>final.output.tail_pb</th>\n",
       "      <th>final.output.tail_sol</th>\n",
       "      <th>final.output.tail_au</th>\n",
       "      <th>primary_cleaner.input.sulfate</th>\n",
       "      <th>...</th>\n",
       "      <th>secondary_cleaner.state.floatbank4_a_air</th>\n",
       "      <th>secondary_cleaner.state.floatbank4_a_level</th>\n",
       "      <th>secondary_cleaner.state.floatbank4_b_air</th>\n",
       "      <th>secondary_cleaner.state.floatbank4_b_level</th>\n",
       "      <th>secondary_cleaner.state.floatbank5_a_air</th>\n",
       "      <th>secondary_cleaner.state.floatbank5_a_level</th>\n",
       "      <th>secondary_cleaner.state.floatbank5_b_air</th>\n",
       "      <th>secondary_cleaner.state.floatbank5_b_level</th>\n",
       "      <th>secondary_cleaner.state.floatbank6_a_air</th>\n",
       "      <th>secondary_cleaner.state.floatbank6_a_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-15 00:00:00</th>\n",
       "      <td>6.055403</td>\n",
       "      <td>9.889648</td>\n",
       "      <td>5.507324</td>\n",
       "      <td>42.192020</td>\n",
       "      <td>70.541216</td>\n",
       "      <td>10.411962</td>\n",
       "      <td>0.895447</td>\n",
       "      <td>16.904297</td>\n",
       "      <td>2.143149</td>\n",
       "      <td>127.092003</td>\n",
       "      <td>...</td>\n",
       "      <td>14.016835</td>\n",
       "      <td>-502.488007</td>\n",
       "      <td>12.099931</td>\n",
       "      <td>-504.715942</td>\n",
       "      <td>9.925633</td>\n",
       "      <td>-498.310211</td>\n",
       "      <td>8.079666</td>\n",
       "      <td>-500.470978</td>\n",
       "      <td>14.151341</td>\n",
       "      <td>-605.841980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-15 01:00:00</th>\n",
       "      <td>6.029369</td>\n",
       "      <td>9.968944</td>\n",
       "      <td>5.257781</td>\n",
       "      <td>42.701629</td>\n",
       "      <td>69.266198</td>\n",
       "      <td>10.462676</td>\n",
       "      <td>0.927452</td>\n",
       "      <td>16.634514</td>\n",
       "      <td>2.224930</td>\n",
       "      <td>125.629232</td>\n",
       "      <td>...</td>\n",
       "      <td>13.992281</td>\n",
       "      <td>-505.503262</td>\n",
       "      <td>11.950531</td>\n",
       "      <td>-501.331529</td>\n",
       "      <td>10.039245</td>\n",
       "      <td>-500.169983</td>\n",
       "      <td>7.984757</td>\n",
       "      <td>-500.582168</td>\n",
       "      <td>13.998353</td>\n",
       "      <td>-599.787184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-15 02:00:00</th>\n",
       "      <td>6.055926</td>\n",
       "      <td>10.213995</td>\n",
       "      <td>5.383759</td>\n",
       "      <td>42.657501</td>\n",
       "      <td>68.116445</td>\n",
       "      <td>10.507046</td>\n",
       "      <td>0.953716</td>\n",
       "      <td>16.208849</td>\n",
       "      <td>2.257889</td>\n",
       "      <td>123.819808</td>\n",
       "      <td>...</td>\n",
       "      <td>14.015015</td>\n",
       "      <td>-502.520901</td>\n",
       "      <td>11.912783</td>\n",
       "      <td>-501.133383</td>\n",
       "      <td>10.070913</td>\n",
       "      <td>-500.129135</td>\n",
       "      <td>8.013877</td>\n",
       "      <td>-500.517572</td>\n",
       "      <td>14.028663</td>\n",
       "      <td>-601.427363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     final.output.concentrate_ag  final.output.concentrate_pb  \\\n",
       "date                                                                            \n",
       "2016-01-15 00:00:00                     6.055403                     9.889648   \n",
       "2016-01-15 01:00:00                     6.029369                     9.968944   \n",
       "2016-01-15 02:00:00                     6.055926                    10.213995   \n",
       "\n",
       "                     final.output.concentrate_sol  \\\n",
       "date                                                \n",
       "2016-01-15 00:00:00                      5.507324   \n",
       "2016-01-15 01:00:00                      5.257781   \n",
       "2016-01-15 02:00:00                      5.383759   \n",
       "\n",
       "                     final.output.concentrate_au  final.output.recovery  \\\n",
       "date                                                                      \n",
       "2016-01-15 00:00:00                    42.192020              70.541216   \n",
       "2016-01-15 01:00:00                    42.701629              69.266198   \n",
       "2016-01-15 02:00:00                    42.657501              68.116445   \n",
       "\n",
       "                     final.output.tail_ag  final.output.tail_pb  \\\n",
       "date                                                              \n",
       "2016-01-15 00:00:00             10.411962              0.895447   \n",
       "2016-01-15 01:00:00             10.462676              0.927452   \n",
       "2016-01-15 02:00:00             10.507046              0.953716   \n",
       "\n",
       "                     final.output.tail_sol  final.output.tail_au  \\\n",
       "date                                                               \n",
       "2016-01-15 00:00:00              16.904297              2.143149   \n",
       "2016-01-15 01:00:00              16.634514              2.224930   \n",
       "2016-01-15 02:00:00              16.208849              2.257889   \n",
       "\n",
       "                     primary_cleaner.input.sulfate  ...  \\\n",
       "date                                                ...   \n",
       "2016-01-15 00:00:00                     127.092003  ...   \n",
       "2016-01-15 01:00:00                     125.629232  ...   \n",
       "2016-01-15 02:00:00                     123.819808  ...   \n",
       "\n",
       "                     secondary_cleaner.state.floatbank4_a_air  \\\n",
       "date                                                            \n",
       "2016-01-15 00:00:00                                 14.016835   \n",
       "2016-01-15 01:00:00                                 13.992281   \n",
       "2016-01-15 02:00:00                                 14.015015   \n",
       "\n",
       "                     secondary_cleaner.state.floatbank4_a_level  \\\n",
       "date                                                              \n",
       "2016-01-15 00:00:00                                 -502.488007   \n",
       "2016-01-15 01:00:00                                 -505.503262   \n",
       "2016-01-15 02:00:00                                 -502.520901   \n",
       "\n",
       "                     secondary_cleaner.state.floatbank4_b_air  \\\n",
       "date                                                            \n",
       "2016-01-15 00:00:00                                 12.099931   \n",
       "2016-01-15 01:00:00                                 11.950531   \n",
       "2016-01-15 02:00:00                                 11.912783   \n",
       "\n",
       "                     secondary_cleaner.state.floatbank4_b_level  \\\n",
       "date                                                              \n",
       "2016-01-15 00:00:00                                 -504.715942   \n",
       "2016-01-15 01:00:00                                 -501.331529   \n",
       "2016-01-15 02:00:00                                 -501.133383   \n",
       "\n",
       "                     secondary_cleaner.state.floatbank5_a_air  \\\n",
       "date                                                            \n",
       "2016-01-15 00:00:00                                  9.925633   \n",
       "2016-01-15 01:00:00                                 10.039245   \n",
       "2016-01-15 02:00:00                                 10.070913   \n",
       "\n",
       "                     secondary_cleaner.state.floatbank5_a_level  \\\n",
       "date                                                              \n",
       "2016-01-15 00:00:00                                 -498.310211   \n",
       "2016-01-15 01:00:00                                 -500.169983   \n",
       "2016-01-15 02:00:00                                 -500.129135   \n",
       "\n",
       "                     secondary_cleaner.state.floatbank5_b_air  \\\n",
       "date                                                            \n",
       "2016-01-15 00:00:00                                  8.079666   \n",
       "2016-01-15 01:00:00                                  7.984757   \n",
       "2016-01-15 02:00:00                                  8.013877   \n",
       "\n",
       "                     secondary_cleaner.state.floatbank5_b_level  \\\n",
       "date                                                              \n",
       "2016-01-15 00:00:00                                 -500.470978   \n",
       "2016-01-15 01:00:00                                 -500.582168   \n",
       "2016-01-15 02:00:00                                 -500.517572   \n",
       "\n",
       "                     secondary_cleaner.state.floatbank6_a_air  \\\n",
       "date                                                            \n",
       "2016-01-15 00:00:00                                 14.151341   \n",
       "2016-01-15 01:00:00                                 13.998353   \n",
       "2016-01-15 02:00:00                                 14.028663   \n",
       "\n",
       "                     secondary_cleaner.state.floatbank6_a_level  \n",
       "date                                                             \n",
       "2016-01-15 00:00:00                                 -605.841980  \n",
       "2016-01-15 01:00:00                                 -599.787184  \n",
       "2016-01-15 02:00:00                                 -601.427363  \n",
       "\n",
       "[3 rows x 86 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "final.output.concentrate_ag      float64\n",
       "final.output.concentrate_pb      float64\n",
       "final.output.concentrate_sol     float64\n",
       "final.output.concentrate_au      float64\n",
       "final.output.recovery            float64\n",
       "final.output.tail_ag             float64\n",
       "final.output.tail_pb             float64\n",
       "final.output.tail_sol            float64\n",
       "final.output.tail_au             float64\n",
       "primary_cleaner.input.sulfate    float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos en train (top 10):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rougher.output.recovery               2573\n",
       "rougher.output.tail_ag                2250\n",
       "rougher.output.tail_sol               2249\n",
       "rougher.output.tail_au                2249\n",
       "secondary_cleaner.output.tail_sol     1986\n",
       "rougher.input.floatbank11_xanthate    1904\n",
       "final.output.recovery                 1521\n",
       "primary_cleaner.input.sulfate         1307\n",
       "primary_cleaner.input.depressant      1262\n",
       "rougher.calculation.au_pb_ratio       1242\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos en test (top 10):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rougher.input.floatbank11_xanthate          353\n",
       "primary_cleaner.input.sulfate               302\n",
       "primary_cleaner.input.depressant            284\n",
       "rougher.input.floatbank10_sulfate           257\n",
       "primary_cleaner.input.xanthate              166\n",
       "rougher.input.floatbank10_xanthate          123\n",
       "rougher.input.feed_sol                       67\n",
       "rougher.input.floatbank11_sulfate            55\n",
       "rougher.input.feed_rate                      40\n",
       "secondary_cleaner.state.floatbank3_a_air     34\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2.1 Carga y exploración inicial de datasets\n",
    "\n",
    "# Función para cargar los datasets\n",
    "def load_datasets(train_path, test_path, full_path):\n",
    "    parse_dates = [\"date\"]\n",
    "    train = pd.read_csv(train_path, parse_dates=parse_dates, index_col=\"date\")\n",
    "    test  = pd.read_csv(test_path,  parse_dates=parse_dates, index_col=\"date\")\n",
    "    full_ = pd.read_csv(full_path,  parse_dates=parse_dates, index_col=\"date\")\n",
    "    return train, test, full_\n",
    "\n",
    "# Carga de datos\n",
    "train, test, full_ = load_datasets(TRAIN_PATH, TEST_PATH, FULL_PATH)\n",
    "\n",
    "# Inspección de dimensiones\n",
    "print(\"Dimensiones de los datasets:\")\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Test :\", test.shape)\n",
    "print(\"Full :\", full_.shape)\n",
    "\n",
    "# Primeras filas de train\n",
    "display(train.head(3))\n",
    "\n",
    "# Tipos de datos en train (primeras 10 columnas)\n",
    "display(train.dtypes.head(10))\n",
    "\n",
    "# Conteo de valores nulos en train y test (top 10)\n",
    "print(\"\\nValores nulos en train (top 10):\")\n",
    "display(train.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\nValores nulos en test (top 10):\")\n",
    "display(test.isna().sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f13a73",
   "metadata": {},
   "source": [
    "### ✅ Conclusión — Subsección 2.1 (Carga y exploración inicial de datasets)\n",
    "\n",
    "- Se cargaron correctamente los tres conjuntos de datos:\n",
    "  - **Train:** 16,860 filas × 86 columnas  \n",
    "  - **Test:** 5,856 filas × 52 columnas  \n",
    "  - **Full:** 22,716 filas × 86 columnas  \n",
    "\n",
    "- El dataset de entrenamiento presenta variables objetivo (`rougher.output.recovery` y `final.output.recovery`) que no están disponibles en el conjunto de prueba, confirmando la separación esperada.\n",
    "\n",
    "- Se identificaron valores nulos significativos en train, especialmente en:\n",
    "  - `rougher.output.recovery` (2,573 nulos)  \n",
    "  - `final.output.recovery` (1,521 nulos)  \n",
    "  - Variables de colas (`tail`) y aditivos como `sulfate` y `depressant`.\n",
    "\n",
    "- En test también se observaron ausencias, aunque en menor cantidad, destacando `rougher.input.floatbank11_xanthate` (353 nulos) y `primary_cleaner.input.sulfate` (302 nulos).\n",
    "\n",
    "- El índice temporal quedó establecido correctamente y las variables muestran tipos de datos numéricos (`float64`) adecuados para el análisis posterior.\n",
    "\n",
    "- Estado: los datos fueron cargados y revisados de manera satisfactoria, quedando listos para la validación de cálculos de recuperación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a646a9",
   "metadata": {},
   "source": [
    "## 2.2 Validación de cálculos de recuperación\n",
    "\n",
    "Se verifica la consistencia de la variable `rougher.output.recovery` recalculándola con la fórmula de dominio:\n",
    "\n",
    "Recovery = [ C × (F − T) ] / [ F × (C − T) ] × 100\n",
    "\n",
    "donde:\n",
    "- C: concentración de oro en el concentrado (`rougher.output.concentrate_au`)\n",
    "- F: concentración de oro en la alimentación (`rougher.input.feed_au`)\n",
    "- T: concentración de oro en las colas (`rougher.output.tail_au`)\n",
    "\n",
    "El valor calculado se compara contra la columna oficial mediante MAE (en puntos porcentuales) y sMAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "626f894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observaciones usadas: 14287\n",
      "MAE (puntos porcentuales): 0.0000\n",
      "sMAPE: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>est</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-15 00:00:00</th>\n",
       "      <td>87.107763</td>\n",
       "      <td>87.107763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-15 01:00:00</th>\n",
       "      <td>86.843261</td>\n",
       "      <td>86.843261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-15 02:00:00</th>\n",
       "      <td>86.842308</td>\n",
       "      <td>86.842308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          true        est\n",
       "date                                     \n",
       "2016-01-15 00:00:00  87.107763  87.107763\n",
       "2016-01-15 01:00:00  86.843261  86.843261\n",
       "2016-01-15 02:00:00  86.842308  86.842308"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2 Validación de cálculos de recuperación (rougher)\n",
    "\n",
    "# sMAPE (sin dependencias externas)\n",
    "def smape(y_true, y_pred, eps=1e-9):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0 + eps\n",
    "    return float(np.mean(np.abs(y_pred - y_true) / denom))\n",
    "\n",
    "# Fórmula del proyecto (porcentaje): [ C*(F - T) ] / [ F*(C - T) ] * 100\n",
    "def compute_recovery_rougher(C, F, T, eps=1e-12):\n",
    "    num = C * (F - T)\n",
    "    den = (F * (C - T)) + eps\n",
    "    return (num / den) * 100.0\n",
    "\n",
    "# Columnas requeridas\n",
    "cols = {\n",
    "    \"C\": \"rougher.output.concentrate_au\",\n",
    "    \"F\": \"rougher.input.feed_au\",\n",
    "    \"T\": \"rougher.output.tail_au\",\n",
    "    \"Y\": \"rougher.output.recovery\",\n",
    "}\n",
    "\n",
    "# Verificación de presencia de columnas\n",
    "missing = [c for c in cols.values() if c not in train.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Columnas faltantes para validar recuperación rougher: {missing}\")\n",
    "\n",
    "# Cálculo y comparación\n",
    "est = compute_recovery_rougher(train[cols[\"C\"]], train[cols[\"F\"]], train[cols[\"T\"]])\n",
    "check = pd.DataFrame({\"true\": train[cols[\"Y\"]], \"est\": est}).dropna()\n",
    "\n",
    "mae_pp = float(np.mean(np.abs(check[\"est\"] - check[\"true\"])))  # puntos porcentuales\n",
    "smape_val = smape(check[\"true\"].values, check[\"est\"].values)\n",
    "\n",
    "print(f\"Observaciones usadas: {len(check)}\")\n",
    "print(f\"MAE (puntos porcentuales): {mae_pp:.4f}\")\n",
    "print(f\"sMAPE: {smape_val:.6f}\")\n",
    "\n",
    "check.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cf68f",
   "metadata": {},
   "source": [
    "### ✅ Conclusión — Subsección 2.2 (Validación de cálculos de recuperación)\n",
    "\n",
    "- La variable `rougher.output.recovery` fue recalculada utilizando la fórmula de dominio:  \n",
    "  Recovery = [ C × (F − T) ] / [ F × (C − T) ] × 100  \n",
    "\n",
    "- El cálculo coincidió de forma exacta con los valores oficiales del dataset:  \n",
    "  - **MAE = 0.0000 puntos porcentuales**  \n",
    "  - **sMAPE = 0.000000**  \n",
    "\n",
    "- Se validaron 14,287 observaciones sin valores nulos, confirmando que la implementación de la fórmula es consistente y que la columna del dataset es confiable para el análisis posterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04657ac4",
   "metadata": {},
   "source": [
    "## 2.3 Análisis de características faltantes en conjunto de prueba\n",
    "\n",
    "El conjunto de prueba no incluye todas las variables presentes en el conjunto de entrenamiento, \n",
    "ya que en la práctica no siempre se disponen de todas las mediciones al momento de la predicción. \n",
    "\n",
    "En esta subsección se identifican las diferencias entre las columnas de train y test, \n",
    "con el objetivo de obtener la intersección de características que se podrán usar en el modelado, \n",
    "evitando la fuga de información y asegurando la consistencia entre ambos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60d6dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columnas en train: 86\n",
      "Total columnas en test : 52\n",
      "Comunes: 52\n",
      "Solo en train: 34\n",
      "Solo en test : 0\n",
      "\n",
      "Ejemplos de columnas solo en train: ['final.output.concentrate_ag', 'final.output.concentrate_au', 'final.output.concentrate_pb', 'final.output.concentrate_sol', 'final.output.recovery', 'final.output.tail_ag', 'final.output.tail_au', 'final.output.tail_pb', 'final.output.tail_sol', 'primary_cleaner.output.concentrate_ag']\n",
      "Ejemplos de columnas solo en test : []\n",
      "\n",
      "Dimensiones alineadas:\n",
      "X_train: (16860, 52) y_train: (16860, 2) X_test: (5856, 52)\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Análisis de características faltantes en conjunto de prueba\n",
    "\n",
    "# Variables objetivo que solo están en train\n",
    "TARGETS = [\"rougher.output.recovery\", \"final.output.recovery\"]\n",
    "\n",
    "# Conjuntos de columnas\n",
    "train_cols = set(train.columns)\n",
    "test_cols  = set(test.columns)\n",
    "\n",
    "# Diferencias y coincidencias\n",
    "solo_en_train = sorted(list(train_cols - test_cols))\n",
    "solo_en_test  = sorted(list(test_cols - train_cols))\n",
    "comunes       = sorted(list(train_cols & test_cols))\n",
    "\n",
    "print(\"Total columnas en train:\", len(train_cols))\n",
    "print(\"Total columnas en test :\", len(test_cols))\n",
    "print(\"Comunes:\", len(comunes))\n",
    "print(\"Solo en train:\", len(solo_en_train))\n",
    "print(\"Solo en test :\", len(solo_en_test))\n",
    "\n",
    "# Mostrar algunas de las diferencias\n",
    "print(\"\\nEjemplos de columnas solo en train:\", solo_en_train[:10])\n",
    "print(\"Ejemplos de columnas solo en test :\", solo_en_test[:10])\n",
    "\n",
    "# Guardar subconjuntos alineados\n",
    "X_train = train[comunes].copy()\n",
    "y_train = train[TARGETS].copy()\n",
    "X_test  = test[comunes].copy()\n",
    "\n",
    "print(\"\\nDimensiones alineadas:\")\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape, \"X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af3fb2a",
   "metadata": {},
   "source": [
    "### ✅ Conclusión — Subsección 2.3 (Análisis de características faltantes en conjunto de prueba)\n",
    "\n",
    "- El conjunto de entrenamiento contiene **86 columnas**, mientras que el de prueba cuenta con **52 columnas**.  \n",
    "- La intersección entre ambos conjuntos es de **52 columnas comunes**, lo que garantiza que el modelado podrá realizarse sin fuga de información.  \n",
    "- Se identificaron **34 columnas exclusivas de train**, incluyendo las variables objetivo (`rougher.output.recovery` y `final.output.recovery`) y otras relacionadas con concentrados y colas finales.  \n",
    "- No existen columnas exclusivas en test, por lo que no se pierden características al alinear los conjuntos.  \n",
    "- Los subconjuntos quedaron alineados de la siguiente forma:  \n",
    "  - `X_train`: (16,860 × 52)  \n",
    "  - `y_train`: (16,860 × 2)  \n",
    "  - `X_test`: (5,856 × 52)  \n",
    "\n",
    "Con esto se asegura que los conjuntos de entrenamiento y prueba están preparados y consistentes para el modelado posterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745aff47",
   "metadata": {},
   "source": [
    "## 2.4 Preprocesamiento de datos\n",
    "\n",
    "En esta subsección se aplican transformaciones iniciales para garantizar la calidad de la información. \n",
    "El preprocesamiento contempla la detección y manejo de valores atípicos, el filtrado de observaciones no válidas \n",
    "y la preparación de los datos para el análisis exploratorio y la construcción del modelo. \n",
    "\n",
    "El objetivo es disponer de un conjunto de datos limpio, consistente y apto para los siguientes pasos del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff59c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados en índice de train: 0\n",
      "\n",
      "Porcentaje de nulos por columna (top 10):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rougher.output.recovery               15.260973\n",
       "rougher.output.tail_ag                13.345196\n",
       "rougher.output.tail_sol               13.339265\n",
       "rougher.output.tail_au                13.339265\n",
       "secondary_cleaner.output.tail_sol     11.779359\n",
       "rougher.input.floatbank11_xanthate    11.293001\n",
       "final.output.recovery                  9.021352\n",
       "primary_cleaner.input.sulfate          7.752076\n",
       "primary_cleaner.input.depressant       7.485172\n",
       "rougher.calculation.au_pb_ratio        7.366548\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proporción de filas válidas según concentraciones:\n",
      "Rougher: 0.0930011862396204\n",
      "Final  : 0.09418742586002372\n",
      "\n",
      "Dimensiones originales: (16860, 86)\n",
      "Dimensiones después del filtrado: (1490, 86)\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Preprocesamiento de datos\n",
    "\n",
    "# 1. Orden y duplicados\n",
    "train_sorted = train.sort_index()\n",
    "duplicados = train_sorted.index.duplicated().sum()\n",
    "print(\"Duplicados en índice de train:\", duplicados)\n",
    "\n",
    "# 2. Nulos: proporción en train (top 10)\n",
    "nulos_pct = train_sorted.isna().mean().sort_values(ascending=False) * 100\n",
    "print(\"\\nPorcentaje de nulos por columna (top 10):\")\n",
    "display(nulos_pct.head(10))\n",
    "\n",
    "# 3. Validación de concentraciones totales en etapas\n",
    "def total_concentration_mask(df, stage_prefix, metals=(\"au\",\"ag\",\"pb\"), min_total=0.0, max_total=1.0):\n",
    "    cols = [c for c in df.columns if c.startswith(stage_prefix) and any(c.endswith(f\"_{m}\") for m in metals)]\n",
    "    if not cols:\n",
    "        return pd.Series(True, index=df.index)  # si no hay columnas, no se filtra nada\n",
    "    total = df[cols].sum(axis=1)\n",
    "    return (total >= min_total) & (total <= max_total)\n",
    "\n",
    "mask_rougher = total_concentration_mask(train_sorted, \"rougher.output\")\n",
    "mask_final   = total_concentration_mask(train_sorted, \"final.output\")\n",
    "\n",
    "print(\"\\nProporción de filas válidas según concentraciones:\")\n",
    "print(\"Rougher:\", mask_rougher.mean())\n",
    "print(\"Final  :\", mask_final.mean())\n",
    "\n",
    "# 4. Dataset limpio preliminar\n",
    "mask_total = mask_rougher & mask_final\n",
    "train_clean = train_sorted[mask_total].copy()\n",
    "\n",
    "print(\"\\nDimensiones originales:\", train_sorted.shape)\n",
    "print(\"Dimensiones después del filtrado:\", train_clean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c007e",
   "metadata": {},
   "source": [
    "### ✅ Conclusión — Subsección 2.4 (Preprocesamiento de datos)\n",
    "\n",
    "- No se detectaron duplicados en el índice temporal, lo que confirma que cada registro corresponde a un instante único del proceso.  \n",
    "\n",
    "- El análisis de valores nulos mostró que varias variables presentan porcentajes de ausencia significativos, \n",
    "  destacando:\n",
    "  - `rougher.output.recovery` (15.26%)  \n",
    "  - `rougher.output.tail_ag` (13.35%)  \n",
    "  - `rougher.output.tail_sol` (13.34%)  \n",
    "  - `rougher.output.tail_au` (13.34%)  \n",
    "  - `final.output.recovery` (9.02%)  \n",
    "\n",
    "- La validación de concentraciones evidenció que solo **~9% de las observaciones** cumplen con los criterios físicos de concentración total en las etapas *rougher* y *final*.  \n",
    "  Esto indica la presencia de un alto volumen de datos anómalos o inconsistentes.  \n",
    "\n",
    "- Como resultado del filtrado por concentraciones válidas, el dataset de entrenamiento se redujo de **16,860 filas a 1,490 filas**.  \n",
    "\n",
    "- Estado: los datos quedaron limpios y consistentes para avanzar al análisis exploratorio, aunque con una reducción considerable de observaciones debido al filtrado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef18df",
   "metadata": {},
   "source": [
    "# 3. Análisis Exploratorio de Datos\n",
    "\n",
    "En esta sección se estudian los patrones y tendencias de las variables más relevantes del proceso, \n",
    "con el fin de comprender mejor el comportamiento de las concentraciones metálicas, \n",
    "detectar posibles anomalías y comparar la consistencia entre los conjuntos de entrenamiento y prueba. \n",
    "\n",
    "El análisis exploratorio permite identificar relaciones clave en los datos \n",
    "y guiar la selección de características para la construcción del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a7735",
   "metadata": {},
   "source": [
    "## 3.1 Evolución de concentraciones metálicas por etapa\n",
    "\n",
    "En esta subsección se analiza la evolución temporal de las concentraciones de metales \n",
    "(Au, Ag y Pb) en diferentes etapas del proceso: alimentación, concentrado y colas. \n",
    "\n",
    "El objetivo es observar cómo varían estas concentraciones a lo largo del tiempo, \n",
    "identificar posibles tendencias y detectar anomalías que puedan afectar el rendimiento del proceso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint12-gold-recovery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
